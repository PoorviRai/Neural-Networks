{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN2_Char.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR1fAWnyf9t8",
        "colab_type": "code",
        "outputId": "5c9434a0-2292-4c58-8c0d-97dec7401354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "!pip install regex"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting regex\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n",
            "\r\u001b[K     |▌                               | 10kB 21.8MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 3.7MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 5.4MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 3.3MB/s eta 0:00:01\r\u001b[K     |██▌                             | 51kB 4.1MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 71kB 5.6MB/s eta 0:00:01\r\u001b[K     |████                            | 81kB 4.3MB/s eta 0:00:01\r\u001b[K     |████▋                           | 92kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 102kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 112kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 122kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 133kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 143kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 153kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 163kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 174kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 184kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 194kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 204kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 215kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 225kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 235kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 245kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 256kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 266kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 276kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 286kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 296kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 307kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 317kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 327kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 337kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 348kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 358kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 368kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 378kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 389kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 399kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 409kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 419kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 430kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 440kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 450kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 460kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 471kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 481kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 491kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 501kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 512kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 522kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 532kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 542kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 552kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 563kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 573kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 583kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 593kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 604kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 614kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 624kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 634kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 645kB 5.2MB/s \n",
            "\u001b[?25hInstalling collected packages: regex\n",
            "Successfully installed regex-2019.11.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BdKuwggfu6r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        },
        "outputId": "b0e00f4a-1485-4298-c559-eb18747d1a32"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Activation, Embedding, Dropout, TimeDistributed\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle\n",
        "import regex as re\n",
        "import random"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyuciZU0f3mS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_words(filepath):\n",
        "    data = open(filepath).read().replace(\" \", \"\").strip()\n",
        "    data = re.sub(r'\\n', '.', data)\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXW2eQFogEBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_vocab(path):\n",
        "    train_data = read_words(path)\n",
        "    vocab = sorted(set(train_data))\n",
        "\n",
        "    # Creating a mapping from unique characters to indices\n",
        "    char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "    idx2char = np.array(vocab)\n",
        "\n",
        "    return char2idx, idx2char"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPXiwjbPgMT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_char_to_integer(filepath, charToIntMap):\n",
        "    data = read_words(filepath)\n",
        "    return np.array([charToIntMap[c] for c in data])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJ4mOoZegQW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "    data_path = \"/tmp/\"\n",
        "    train_path = data_path + \"ptb.char.train.txt\"\n",
        "    valid_path = data_path + \"ptb.char.valid.txt\"\n",
        "    test_path = data_path + \"ptb.char.test.txt\"\n",
        "\n",
        "    char2idx, idx2char = build_vocab(train_path)\n",
        "    train_data = convert_char_to_integer(train_path, char2idx)\n",
        "    valid_data = convert_char_to_integer(valid_path, char2idx)\n",
        "    test_data = convert_char_to_integer(test_path, char2idx)\n",
        "    vocabulary = len(char2idx)\n",
        "\n",
        "    return train_data, valid_data, test_data, vocabulary, idx2char\n",
        "\n",
        "train_data, valid_data, test_data, vocabulary, reversed_dictionary = load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UpcuMSxgZNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class KerasBatchGenerator(object):\n",
        "    def __init__(self, data, num_steps, batch_size, vocabulary, skip_step = 5):\n",
        "        self.data = data\n",
        "        self.num_steps = num_steps\n",
        "        self.batch_size = batch_size\n",
        "        self.vocabulary = vocabulary\n",
        "        self.current_idx = 0\n",
        "        self.skip_step = skip_step\n",
        "\n",
        "    def generate(self):\n",
        "        x = np.zeros((self.batch_size, self.num_steps))\n",
        "        y = np.zeros((self.batch_size, self.num_steps, self.vocabulary))\n",
        "        while True:\n",
        "            for i in range(self.batch_size):\n",
        "                if self.current_idx + self.num_steps >= len(self.data):\n",
        "                    # reset index\n",
        "                    self.current_idx = 0\n",
        "\n",
        "                x[i, :] = self.data[self.current_idx:self.current_idx + self.num_steps]\n",
        "                temp_y = self.data[self.current_idx + 1:self.current_idx + self.num_steps + 1]\n",
        "                \n",
        "                y[i, :, :] = to_categorical(temp_y, num_classes=self.vocabulary)\n",
        "                self.current_idx += self.skip_step\n",
        "\n",
        "            yield x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EZe9CjYgh3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_steps = 100\n",
        "batch_size = 64\n",
        "train_data_generator = KerasBatchGenerator(train_data, num_steps, batch_size, vocabulary,\n",
        "                                           skip_step=num_steps)\n",
        "valid_data_generator = KerasBatchGenerator(valid_data, num_steps, batch_size, vocabulary,\n",
        "                                           skip_step=num_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPr1-wWVgoDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perplexity(y_true, y_pred):\n",
        "    return K.exp(K.mean(K.categorical_crossentropy(y_true, y_pred)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdIlYjirgtni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jMqTryHgxK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(data, num_predict=1000):\n",
        "    generated = ''\n",
        "    start_index = random.randint(0, len(data) - num_steps - 1)\n",
        "    sequence = data[start_index: start_index + num_steps]\n",
        "    for i in sequence:\n",
        "        generated += reversed_dictionary[i]\n",
        "        \n",
        "    sequence = np.array([sequence])\n",
        "    print('----- Generating with seed: \"' + generated + '\"')\n",
        "    print()\n",
        "    temperature = 1.0\n",
        "    seq = sequence\n",
        "    for i in range(num_predict):\n",
        "        predictions = model.predict(seq)\n",
        "        predicted_id = sample(predictions[:, num_steps-1, :][0])\n",
        "        \n",
        "        next_char = reversed_dictionary[predicted_id]\n",
        "        generated += next_char\n",
        "        \n",
        "        seq = np.array([np.append(seq[0][1:], [predicted_id])])\n",
        "        \n",
        "    return generated"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRkzY9dOg2zx",
        "colab_type": "code",
        "outputId": "1341e95f-245c-465e-8137-84f149802fab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hidden_size = 300\n",
        "use_dropout=True\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocabulary, hidden_size, input_length=num_steps))\n",
        "model.add(LSTM(hidden_size, return_sequences=True))\n",
        "if use_dropout:\n",
        "    model.add(Dropout(0.5))\n",
        "model.add(LSTM(hidden_size, return_sequences=True))\n",
        "if use_dropout:\n",
        "    model.add(Dropout(0.5))\n",
        "model.add(TimeDistributed(Dense(vocabulary)))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy', perplexity])\n",
        "\n",
        "print(model.summary())\n",
        "data_path = \"/tmp/\"\n",
        "checkpointer = ModelCheckpoint(filepath=data_path + 'final_run_char/model-{epoch:02d}.hdf5', verbose=1)\n",
        "\n",
        "#print(\"loading epoch 19 saved model\")\n",
        "#model.load_weights(data_path+\"/model-19.hdf5\")\n",
        "\n",
        "num_epochs = 50\n",
        "callback_history = model.fit_generator(train_data_generator.generate(), len(train_data)//(batch_size*num_steps), num_epochs,\n",
        "                        validation_data=valid_data_generator.generate(),\n",
        "                        validation_steps=len(valid_data)//(batch_size*num_steps))#, callbacks=[checkpointer])\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 100, 300)          14700     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100, 300)          721200    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100, 300)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100, 300)          721200    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100, 300)          0         \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 100, 49)           14749     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 100, 49)           0         \n",
            "=================================================================\n",
            "Total params: 1,471,849\n",
            "Trainable params: 1,471,849\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/50\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "783/783 [==============================] - 227s 290ms/step - loss: 2.2576 - categorical_accuracy: 0.3615 - perplexity: 11.1658 - val_loss: 1.6955 - val_categorical_accuracy: 0.5097 - val_perplexity: 6.4383\n",
            "Epoch 2/50\n",
            "783/783 [==============================] - 222s 283ms/step - loss: 1.7790 - categorical_accuracy: 0.4982 - perplexity: 7.7552 - val_loss: 1.4496 - val_categorical_accuracy: 0.5720 - val_perplexity: 4.2758\n",
            "Epoch 3/50\n",
            "783/783 [==============================] - 222s 283ms/step - loss: 1.6353 - categorical_accuracy: 0.5392 - perplexity: 6.7160 - val_loss: 1.3200 - val_categorical_accuracy: 0.5996 - val_perplexity: 3.7508\n",
            "Epoch 4/50\n",
            "783/783 [==============================] - 223s 284ms/step - loss: 1.5366 - categorical_accuracy: 0.5628 - perplexity: 6.4387 - val_loss: 1.3402 - val_categorical_accuracy: 0.6032 - val_perplexity: 6.1959\n",
            "Epoch 5/50\n",
            "783/783 [==============================] - 223s 285ms/step - loss: 1.4943 - categorical_accuracy: 0.5743 - perplexity: 6.6984 - val_loss: 1.3195 - val_categorical_accuracy: 0.6099 - val_perplexity: 7.0832\n",
            "Epoch 6/50\n",
            "783/783 [==============================] - 223s 284ms/step - loss: 1.4940 - categorical_accuracy: 0.5786 - perplexity: 6.6495 - val_loss: 1.2240 - val_categorical_accuracy: 0.6261 - val_perplexity: 3.4072\n",
            "Epoch 7/50\n",
            "783/783 [==============================] - 224s 285ms/step - loss: 1.4481 - categorical_accuracy: 0.5877 - perplexity: 5.7824 - val_loss: 1.2087 - val_categorical_accuracy: 0.6304 - val_perplexity: 3.3554\n",
            "Epoch 8/50\n",
            "783/783 [==============================] - 223s 285ms/step - loss: 1.4293 - categorical_accuracy: 0.5928 - perplexity: 6.0726 - val_loss: 1.2632 - val_categorical_accuracy: 0.6241 - val_perplexity: 6.1350\n",
            "Epoch 9/50\n",
            "783/783 [==============================] - 223s 285ms/step - loss: 1.5119 - categorical_accuracy: 0.5823 - perplexity: 7.1312 - val_loss: 1.2170 - val_categorical_accuracy: 0.6327 - val_perplexity: 3.4074\n",
            "Epoch 10/50\n",
            "783/783 [==============================] - 223s 285ms/step - loss: 1.5025 - categorical_accuracy: 0.5851 - perplexity: 7.5550 - val_loss: 1.1853 - val_categorical_accuracy: 0.6372 - val_perplexity: 3.2791\n",
            "Epoch 11/50\n",
            "783/783 [==============================] - 224s 285ms/step - loss: 1.5046 - categorical_accuracy: 0.5861 - perplexity: 7.6196 - val_loss: 1.2516 - val_categorical_accuracy: 0.6292 - val_perplexity: 6.5423\n",
            "Epoch 12/50\n",
            "783/783 [==============================] - 222s 284ms/step - loss: 1.4098 - categorical_accuracy: 0.6013 - perplexity: 6.8983 - val_loss: 1.1684 - val_categorical_accuracy: 0.6415 - val_perplexity: 3.2243\n",
            "Epoch 13/50\n",
            "783/783 [==============================] - 223s 284ms/step - loss: 1.4486 - categorical_accuracy: 0.5964 - perplexity: 6.3991 - val_loss: 1.1697 - val_categorical_accuracy: 0.6420 - val_perplexity: 3.2276\n",
            "Epoch 14/50\n",
            "783/783 [==============================] - 224s 286ms/step - loss: 1.4519 - categorical_accuracy: 0.5963 - perplexity: 6.7881 - val_loss: 1.1650 - val_categorical_accuracy: 0.6426 - val_perplexity: 3.2123\n",
            "Epoch 15/50\n",
            "783/783 [==============================] - 223s 284ms/step - loss: 1.4031 - categorical_accuracy: 0.6044 - perplexity: 6.3197 - val_loss: 1.1550 - val_categorical_accuracy: 0.6447 - val_perplexity: 3.1820\n",
            "Epoch 16/50\n",
            "783/783 [==============================] - 222s 283ms/step - loss: 1.3874 - categorical_accuracy: 0.6073 - perplexity: 5.9535 - val_loss: 1.1538 - val_categorical_accuracy: 0.6452 - val_perplexity: 3.1760\n",
            "Epoch 17/50\n",
            "783/783 [==============================] - 222s 283ms/step - loss: 1.4200 - categorical_accuracy: 0.6036 - perplexity: 7.5206 - val_loss: 1.1507 - val_categorical_accuracy: 0.6470 - val_perplexity: 3.1674\n",
            "Epoch 18/50\n",
            "783/783 [==============================] - 222s 284ms/step - loss: 1.3786 - categorical_accuracy: 0.6099 - perplexity: 6.9817 - val_loss: 1.2146 - val_categorical_accuracy: 0.6388 - val_perplexity: 5.8147\n",
            "Epoch 19/50\n",
            "783/783 [==============================] - 221s 283ms/step - loss: 1.3815 - categorical_accuracy: 0.6101 - perplexity: 6.2959 - val_loss: 1.1568 - val_categorical_accuracy: 0.6460 - val_perplexity: 3.2148\n",
            "Epoch 20/50\n",
            "783/783 [==============================] - 221s 283ms/step - loss: 1.3706 - categorical_accuracy: 0.6123 - perplexity: 6.3440 - val_loss: 1.1379 - val_categorical_accuracy: 0.6493 - val_perplexity: 3.1280\n",
            "Epoch 21/50\n",
            "783/783 [==============================] - 223s 284ms/step - loss: 1.3844 - categorical_accuracy: 0.6106 - perplexity: 6.7649 - val_loss: 1.1382 - val_categorical_accuracy: 0.6501 - val_perplexity: 3.1285\n",
            "Epoch 22/50\n",
            "783/783 [==============================] - 221s 282ms/step - loss: 1.3492 - categorical_accuracy: 0.6159 - perplexity: 5.8957 - val_loss: 1.2100 - val_categorical_accuracy: 0.6406 - val_perplexity: 8.3358\n",
            "Epoch 23/50\n",
            "783/783 [==============================] - 220s 281ms/step - loss: 1.3914 - categorical_accuracy: 0.6108 - perplexity: 7.8743 - val_loss: 1.1555 - val_categorical_accuracy: 0.6480 - val_perplexity: 3.1818\n",
            "Epoch 24/50\n",
            "783/783 [==============================] - 221s 283ms/step - loss: 1.3625 - categorical_accuracy: 0.6149 - perplexity: 5.6857 - val_loss: 1.1377 - val_categorical_accuracy: 0.6516 - val_perplexity: 3.1261\n",
            "Epoch 25/50\n",
            "783/783 [==============================] - 222s 284ms/step - loss: 1.3814 - categorical_accuracy: 0.6125 - perplexity: 7.2151 - val_loss: 1.1422 - val_categorical_accuracy: 0.6514 - val_perplexity: 3.1410\n",
            "Epoch 26/50\n",
            "783/783 [==============================] - 226s 288ms/step - loss: 1.3884 - categorical_accuracy: 0.6116 - perplexity: 6.5997 - val_loss: 1.1332 - val_categorical_accuracy: 0.6520 - val_perplexity: 3.1124\n",
            "Epoch 27/50\n",
            "783/783 [==============================] - 224s 286ms/step - loss: 1.4237 - categorical_accuracy: 0.6075 - perplexity: 7.5002 - val_loss: 1.1445 - val_categorical_accuracy: 0.6520 - val_perplexity: 3.1478\n",
            "Epoch 28/50\n",
            "783/783 [==============================] - 224s 287ms/step - loss: 1.3501 - categorical_accuracy: 0.6177 - perplexity: 5.8134 - val_loss: 1.1298 - val_categorical_accuracy: 0.6530 - val_perplexity: 3.1022\n",
            "Epoch 29/50\n",
            "783/783 [==============================] - 226s 289ms/step - loss: 1.3330 - categorical_accuracy: 0.6202 - perplexity: 6.1386 - val_loss: 1.2059 - val_categorical_accuracy: 0.6434 - val_perplexity: 9.7360\n",
            "Epoch 30/50\n",
            "783/783 [==============================] - 224s 286ms/step - loss: 1.3183 - categorical_accuracy: 0.6229 - perplexity: 6.2714 - val_loss: 1.1293 - val_categorical_accuracy: 0.6531 - val_perplexity: 3.1005\n",
            "Epoch 31/50\n",
            "783/783 [==============================] - 226s 288ms/step - loss: 1.4022 - categorical_accuracy: 0.6114 - perplexity: 7.0396 - val_loss: 1.1315 - val_categorical_accuracy: 0.6529 - val_perplexity: 3.1070\n",
            "Epoch 32/50\n",
            "783/783 [==============================] - 226s 289ms/step - loss: 1.3455 - categorical_accuracy: 0.6194 - perplexity: 6.0700 - val_loss: 1.1320 - val_categorical_accuracy: 0.6540 - val_perplexity: 3.1091\n",
            "Epoch 33/50\n",
            "783/783 [==============================] - 227s 290ms/step - loss: 1.3715 - categorical_accuracy: 0.6161 - perplexity: 6.6211 - val_loss: 1.1221 - val_categorical_accuracy: 0.6548 - val_perplexity: 3.0783\n",
            "Epoch 34/50\n",
            "783/783 [==============================] - 227s 290ms/step - loss: 1.3543 - categorical_accuracy: 0.6186 - perplexity: 6.8209 - val_loss: 1.1731 - val_categorical_accuracy: 0.6479 - val_perplexity: 3.8750\n",
            "Epoch 35/50\n",
            "783/783 [==============================] - 227s 289ms/step - loss: 1.3504 - categorical_accuracy: 0.6198 - perplexity: 6.3103 - val_loss: 1.1315 - val_categorical_accuracy: 0.6539 - val_perplexity: 3.1068\n",
            "Epoch 36/50\n",
            "783/783 [==============================] - 227s 290ms/step - loss: 1.3581 - categorical_accuracy: 0.6189 - perplexity: 6.7160 - val_loss: 1.1922 - val_categorical_accuracy: 0.6456 - val_perplexity: 6.9980\n",
            "Epoch 37/50\n",
            "783/783 [==============================] - 219s 280ms/step - loss: 1.3535 - categorical_accuracy: 0.6196 - perplexity: 7.0373 - val_loss: 1.1248 - val_categorical_accuracy: 0.6548 - val_perplexity: 3.0880\n",
            "Epoch 38/50\n",
            "783/783 [==============================] - 213s 272ms/step - loss: 1.2775 - categorical_accuracy: 0.6297 - perplexity: 5.6306 - val_loss: 1.1175 - val_categorical_accuracy: 0.6553 - val_perplexity: 3.0643\n",
            "Epoch 39/50\n",
            "783/783 [==============================] - 218s 278ms/step - loss: 1.3921 - categorical_accuracy: 0.6141 - perplexity: 7.3736 - val_loss: 1.1184 - val_categorical_accuracy: 0.6562 - val_perplexity: 3.0681\n",
            "Epoch 40/50\n",
            "783/783 [==============================] - 226s 289ms/step - loss: 1.4008 - categorical_accuracy: 0.6127 - perplexity: 6.1722 - val_loss: 1.1967 - val_categorical_accuracy: 0.6463 - val_perplexity: 8.4632\n",
            "Epoch 41/50\n",
            "783/783 [==============================] - 229s 293ms/step - loss: 1.3439 - categorical_accuracy: 0.6217 - perplexity: 6.8880 - val_loss: 1.1179 - val_categorical_accuracy: 0.6569 - val_perplexity: 3.0654\n",
            "Epoch 42/50\n",
            "783/783 [==============================] - 232s 297ms/step - loss: 1.3556 - categorical_accuracy: 0.6202 - perplexity: 6.7655 - val_loss: 1.1133 - val_categorical_accuracy: 0.6575 - val_perplexity: 3.0530\n",
            "Epoch 43/50\n",
            "783/783 [==============================] - 233s 298ms/step - loss: 1.3455 - categorical_accuracy: 0.6211 - perplexity: 6.5005 - val_loss: 1.1581 - val_categorical_accuracy: 0.6540 - val_perplexity: 3.1897\n",
            "Epoch 44/50\n",
            "783/783 [==============================] - 233s 298ms/step - loss: 1.3619 - categorical_accuracy: 0.6192 - perplexity: 6.3607 - val_loss: 1.1322 - val_categorical_accuracy: 0.6561 - val_perplexity: 3.1090\n",
            "Epoch 45/50\n",
            "783/783 [==============================] - 233s 298ms/step - loss: 1.3720 - categorical_accuracy: 0.6184 - perplexity: 6.2469 - val_loss: 1.1315 - val_categorical_accuracy: 0.6555 - val_perplexity: 3.1075\n",
            "Epoch 46/50\n",
            "783/783 [==============================] - 234s 298ms/step - loss: 1.3595 - categorical_accuracy: 0.6199 - perplexity: 6.0142 - val_loss: 1.1156 - val_categorical_accuracy: 0.6581 - val_perplexity: 3.0626\n",
            "Epoch 47/50\n",
            "783/783 [==============================] - 234s 299ms/step - loss: 1.3431 - categorical_accuracy: 0.6227 - perplexity: 6.0688 - val_loss: 1.1919 - val_categorical_accuracy: 0.6476 - val_perplexity: 7.0584\n",
            "Epoch 48/50\n",
            "783/783 [==============================] - 234s 299ms/step - loss: 1.3726 - categorical_accuracy: 0.6187 - perplexity: 6.6172 - val_loss: 1.1653 - val_categorical_accuracy: 0.6512 - val_perplexity: 3.5270\n",
            "Epoch 49/50\n",
            "783/783 [==============================] - 233s 297ms/step - loss: 1.3704 - categorical_accuracy: 0.6188 - perplexity: 6.9629 - val_loss: 1.2117 - val_categorical_accuracy: 0.6446 - val_perplexity: 7.2690\n",
            "Epoch 50/50\n",
            "783/783 [==============================] - 226s 289ms/step - loss: 1.3140 - categorical_accuracy: 0.6268 - perplexity: 6.0755 - val_loss: 1.1089 - val_categorical_accuracy: 0.6583 - val_perplexity: 3.0384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPJEpKmc4iMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(data_path + \"/final_model.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkFcGAscg9CN",
        "colab_type": "code",
        "outputId": "d5d2dbb4-36c4-416a-b8c5-3a70065ddbd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "plt.plot(callback_history.history['perplexity'])\n",
        "plt.plot(callback_history.history['val_perplexity'])\n",
        "plt.title('Model Perplexity')\n",
        "plt.ylabel('Perplexity')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.savefig('nn_4_50.png')\n",
        "plt.show()\n",
        "\n",
        "#model = load_model(data_path + \"/final_run_char/model-50.hdf5\", custom_objects={'perplexity':perplexity})\n",
        "#model = load_model(\"model-10.hdf5\")\n",
        "print(predict(test_data))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----- Generating with seed: \"_a_landmark_in_dutch_corporate_law_because_the_lawsuit_<unk>_plans_to_file_would_be_the_first_to_cha\"\n",
            "\n",
            "_a_landmark_in_dutch_corporate_law_because_the_lawsuit_<unk>_plans_to_file_would_be_the_first_to_charles_chairman_<unk>_<unk>_&_co._which_opening_mr._<unk>_'s_warrings_of_texas_which_is_convertible_ffrom_a_political_generally_net_income_rates_federal_concerns_in_other_water_oil_plants_traders_'.we_'ll_leave_the_existed_and_the_<unk>_features_released_on_the_<unk>_flue_short-term_millions_of_edding_to_low_visit_in_an_$_N_million_operations_by__doubt_in_N_wolided_at_N.early_N_N_N_earnings_in_those_years_and_N_N_at_the_distributor_of_position_for_new_york_category_you_said_in_treasury_chicago_budgets_to_all_mikell_even_for_which_of_him_and_the_firm_your_deNoN.in_<unk>.while_a_different_cdamp_fnations_in_los_angeles_countries_and_approached_the_recent_cuts_stayed_by_the_house_rade_of_local_office_for_<unk>_acquisitions.in_required_serious_success_for_a_new_magazine_in_pension_trading.pase_the_biggest_hinds_who_and_<unk>ed_the_best_telephone_whiten_using_one_specialrty_a_fewares_digital_for_the_kemper_on_same_big_offering_of_washington_but_a_lokel_of_schedule_says_general_company_'s_neith\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}