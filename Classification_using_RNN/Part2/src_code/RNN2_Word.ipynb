{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN2_Word.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QBVbiuN4yY8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        },
        "outputId": "7cd4d51e-b611-433c-d4bf-8112c949476d"
      },
      "source": [
        "import collections\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Activation, Embedding, Dropout, TimeDistributed\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nzk0XTKC4-qA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_words(filename):\n",
        "    with open(filename) as f:\n",
        "        return f.read().replace(\"\\n\", \"<eos>\").lower().split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBO7wSAP5IAe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_vocab(filename):\n",
        "    data = read_words(filename)\n",
        "\n",
        "    counter = collections.Counter(data)\n",
        "    count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n",
        "\n",
        "    words, _ = list(zip(*count_pairs))\n",
        "    word_to_id = dict(zip(words, range(len(words))))\n",
        "\n",
        "    return word_to_id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZi1_y4O5KAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def file_to_word_ids(filename, word_to_id):\n",
        "    data = read_words(filename)\n",
        "    return [word_to_id[word] for word in data if word in word_to_id]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfS-IV4L5XAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "    data_path = \"/tmp/\"\n",
        "    train_path = data_path + \"ptb.train.txt\"\n",
        "    valid_path = data_path + \"ptb.valid.txt\"\n",
        "    test_path = data_path + \"ptb.test.txt\"\n",
        "\n",
        "    word_to_id = build_vocab(train_path)\n",
        "    train_data = file_to_word_ids(train_path, word_to_id)\n",
        "    valid_data = file_to_word_ids(valid_path, word_to_id)\n",
        "    test_data = file_to_word_ids(test_path, word_to_id)\n",
        "    vocabulary = len(word_to_id)\n",
        "    reversed_dictionary = dict(zip(word_to_id.values(), word_to_id.keys()))\n",
        "\n",
        "    return train_data, valid_data, test_data, vocabulary, reversed_dictionary\n",
        "\n",
        "train_data, valid_data, test_data, vocabulary, reversed_dictionary = load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnAfdriB5j4u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class KerasBatchGenerator(object):\n",
        "    def __init__(self, data, num_steps, batch_size, vocabulary, skip_step = 5):\n",
        "        self.data = data\n",
        "        self.num_steps = num_steps\n",
        "        self.batch_size = batch_size\n",
        "        self.vocabulary = vocabulary\n",
        "        self.current_idx = 0\n",
        "        self.skip_step = skip_step\n",
        "\n",
        "    def generate(self):\n",
        "        x = np.zeros((self.batch_size, self.num_steps))\n",
        "        y = np.zeros((self.batch_size, self.num_steps, self.vocabulary))\n",
        "        while True:\n",
        "            for i in range(self.batch_size):\n",
        "                if self.current_idx + self.num_steps >= len(self.data):\n",
        "                    self.current_idx = 0\n",
        "\n",
        "                x[i, :] = self.data[self.current_idx:self.current_idx + self.num_steps]\n",
        "                temp_y = self.data[self.current_idx + 1:self.current_idx + self.num_steps + 1]\n",
        "                \n",
        "                y[i, :, :] = to_categorical(temp_y, num_classes=self.vocabulary)\n",
        "                self.current_idx += self.skip_step\n",
        "                \n",
        "            yield x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wJs3e-G53FP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_steps = 32\n",
        "batch_size = 32\n",
        "train_data_generator = KerasBatchGenerator(train_data, num_steps, batch_size, vocabulary,\n",
        "                                           skip_step=num_steps)\n",
        "valid_data_generator = KerasBatchGenerator(valid_data, num_steps, batch_size, vocabulary,\n",
        "                                           skip_step=num_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnHSuqUH57xX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perplexity(y_true, y_pred):\n",
        "    return K.exp(K.mean(K.categorical_crossentropy(y_true, y_pred)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DxdbrXc5-j2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9d1c8e72-05c7-48b9-e3d5-d59564cdcb7b"
      },
      "source": [
        "hidden_size = 300\n",
        "use_dropout=True\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocabulary, hidden_size, input_length=num_steps))\n",
        "model.add(LSTM(hidden_size, return_sequences=True))\n",
        "if use_dropout:\n",
        "    model.add(Dropout(0.5))\n",
        "model.add(LSTM(hidden_size, return_sequences=True))\n",
        "if use_dropout:\n",
        "    model.add(Dropout(0.5))\n",
        "model.add(TimeDistributed(Dense(vocabulary)))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy', perplexity])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "data_path = \"/tmp/\"\n",
        "checkpointer = ModelCheckpoint(filepath=data_path + 'final_run/model-{epoch:02d}.hdf5', verbose=1)\n",
        "\n",
        "#print(\"loading epoch 19 saved model\")\n",
        "#model.load_weights(data_path+\"/model-19.hdf5\")\n",
        "\n",
        "num_epochs = 50\n",
        "callback_history = model.fit_generator(train_data_generator.generate(), len(train_data)//(batch_size*num_steps), num_epochs,\n",
        "                        validation_data=valid_data_generator.generate(),\n",
        "                        validation_steps=len(valid_data)//(batch_size*num_steps))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 32, 300)           3000000   \n",
            "_________________________________________________________________\n",
            "lstm_17 (LSTM)               (None, 32, 300)           721200    \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 32, 300)           0         \n",
            "_________________________________________________________________\n",
            "lstm_18 (LSTM)               (None, 32, 300)           721200    \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 32, 300)           0         \n",
            "_________________________________________________________________\n",
            "time_distributed_8 (TimeDist (None, 32, 10000)         3010000   \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 32, 10000)         0         \n",
            "=================================================================\n",
            "Total params: 7,452,400\n",
            "Trainable params: 7,452,400\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "907/907 [==============================] - 215s 237ms/step - loss: 6.8947 - categorical_accuracy: 0.0503 - perplexity: 1072.6792 - val_loss: 6.7479 - val_categorical_accuracy: 0.0463 - val_perplexity: 869.0976\n",
            "Epoch 2/50\n",
            "907/907 [==============================] - 211s 233ms/step - loss: 6.8105 - categorical_accuracy: 0.0510 - perplexity: 923.0158 - val_loss: 6.7420 - val_categorical_accuracy: 0.0344 - val_perplexity: 864.9372\n",
            "Epoch 3/50\n",
            "907/907 [==============================] - 212s 233ms/step - loss: 6.8137 - categorical_accuracy: 0.0513 - perplexity: 925.2168 - val_loss: 6.7251 - val_categorical_accuracy: 0.0356 - val_perplexity: 852.5883\n",
            "Epoch 4/50\n",
            "907/907 [==============================] - 212s 234ms/step - loss: 6.8037 - categorical_accuracy: 0.0516 - perplexity: 916.2425 - val_loss: 6.7367 - val_categorical_accuracy: 0.0358 - val_perplexity: 864.5525\n",
            "Epoch 5/50\n",
            "907/907 [==============================] - 211s 232ms/step - loss: 6.6547 - categorical_accuracy: 0.0667 - perplexity: 790.6834 - val_loss: 6.4247 - val_categorical_accuracy: 0.1047 - val_perplexity: 630.3301\n",
            "Epoch 6/50\n",
            "907/907 [==============================] - 211s 233ms/step - loss: 6.4301 - categorical_accuracy: 0.0996 - perplexity: 641.2215 - val_loss: 6.1899 - val_categorical_accuracy: 0.1246 - val_perplexity: 502.6821\n",
            "Epoch 7/50\n",
            "907/907 [==============================] - 211s 233ms/step - loss: 6.3166 - categorical_accuracy: 0.1109 - perplexity: 585.9900 - val_loss: 6.0671 - val_categorical_accuracy: 0.1397 - val_perplexity: 449.1970\n",
            "Epoch 8/50\n",
            "907/907 [==============================] - 212s 234ms/step - loss: 6.2089 - categorical_accuracy: 0.1221 - perplexity: 538.5054 - val_loss: 5.9087 - val_categorical_accuracy: 0.1522 - val_perplexity: 383.6093\n",
            "Epoch 9/50\n",
            "907/907 [==============================] - 211s 233ms/step - loss: 6.1044 - categorical_accuracy: 0.1310 - perplexity: 498.1287 - val_loss: 5.8044 - val_categorical_accuracy: 0.1596 - val_perplexity: 348.5804\n",
            "Epoch 10/50\n",
            "907/907 [==============================] - 210s 232ms/step - loss: 6.0407 - categorical_accuracy: 0.1356 - perplexity: 477.0771 - val_loss: 5.7511 - val_categorical_accuracy: 0.1646 - val_perplexity: 329.5960\n",
            "Epoch 11/50\n",
            "907/907 [==============================] - 211s 232ms/step - loss: 5.9692 - categorical_accuracy: 0.1419 - perplexity: 451.7087 - val_loss: 5.7177 - val_categorical_accuracy: 0.1667 - val_perplexity: 320.4819\n",
            "Epoch 12/50\n",
            "907/907 [==============================] - 211s 233ms/step - loss: 5.9173 - categorical_accuracy: 0.1459 - perplexity: 438.7014 - val_loss: 5.6106 - val_categorical_accuracy: 0.1762 - val_perplexity: 290.0407\n",
            "Epoch 13/50\n",
            "907/907 [==============================] - 211s 233ms/step - loss: 5.9438 - categorical_accuracy: 0.1425 - perplexity: 456.1401 - val_loss: 5.7172 - val_categorical_accuracy: 0.1729 - val_perplexity: 319.9779\n",
            "Epoch 14/50\n",
            "907/907 [==============================] - 211s 233ms/step - loss: 5.8824 - categorical_accuracy: 0.1471 - perplexity: 431.4154 - val_loss: 5.6397 - val_categorical_accuracy: 0.1757 - val_perplexity: 296.7243\n",
            "Epoch 15/50\n",
            "907/907 [==============================] - 212s 234ms/step - loss: 5.8064 - categorical_accuracy: 0.1533 - perplexity: 411.0478 - val_loss: 5.5743 - val_categorical_accuracy: 0.1845 - val_perplexity: 284.9469\n",
            "Epoch 16/50\n",
            "907/907 [==============================] - 211s 232ms/step - loss: 5.7659 - categorical_accuracy: 0.1569 - perplexity: 402.9790 - val_loss: 5.6004 - val_categorical_accuracy: 0.1823 - val_perplexity: 283.3984\n",
            "Epoch 17/50\n",
            "907/907 [==============================] - 211s 233ms/step - loss: 5.7874 - categorical_accuracy: 0.1547 - perplexity: 415.4406 - val_loss: 5.5308 - val_categorical_accuracy: 0.1883 - val_perplexity: 273.6414\n",
            "Epoch 18/50\n",
            "907/907 [==============================] - 211s 233ms/step - loss: 5.7076 - categorical_accuracy: 0.1619 - perplexity: 387.1743 - val_loss: 5.4698 - val_categorical_accuracy: 0.1925 - val_perplexity: 253.8248\n",
            "Epoch 19/50\n",
            "907/907 [==============================] - 209s 230ms/step - loss: 5.6806 - categorical_accuracy: 0.1637 - perplexity: 392.3899 - val_loss: 5.4810 - val_categorical_accuracy: 0.1927 - val_perplexity: 254.0228\n",
            "Epoch 20/50\n",
            "907/907 [==============================] - 211s 233ms/step - loss: 5.7200 - categorical_accuracy: 0.1593 - perplexity: 400.9456 - val_loss: 5.5219 - val_categorical_accuracy: 0.1902 - val_perplexity: 274.6385\n",
            "Epoch 21/50\n",
            "907/907 [==============================] - 212s 233ms/step - loss: 5.7491 - categorical_accuracy: 0.1567 - perplexity: 405.5288 - val_loss: 5.4557 - val_categorical_accuracy: 0.1959 - val_perplexity: 254.3394\n",
            "Epoch 22/50\n",
            "907/907 [==============================] - 212s 234ms/step - loss: 5.6337 - categorical_accuracy: 0.1661 - perplexity: 379.1627 - val_loss: 5.4641 - val_categorical_accuracy: 0.1951 - val_perplexity: 260.1437\n",
            "Epoch 23/50\n",
            "907/907 [==============================] - 211s 233ms/step - loss: 5.6004 - categorical_accuracy: 0.1690 - perplexity: 360.0524 - val_loss: 5.3929 - val_categorical_accuracy: 0.2008 - val_perplexity: 240.3008\n",
            "Epoch 24/50\n",
            "907/907 [==============================] - 210s 231ms/step - loss: 5.5843 - categorical_accuracy: 0.1707 - perplexity: 361.0210 - val_loss: 5.4494 - val_categorical_accuracy: 0.1964 - val_perplexity: 249.7595\n",
            "Epoch 25/50\n",
            "907/907 [==============================] - 211s 233ms/step - loss: 5.6094 - categorical_accuracy: 0.1679 - perplexity: 365.2338 - val_loss: 5.4985 - val_categorical_accuracy: 0.1906 - val_perplexity: 269.7246\n",
            "Epoch 26/50\n",
            "907/907 [==============================] - 212s 233ms/step - loss: 5.5670 - categorical_accuracy: 0.1715 - perplexity: 362.7553 - val_loss: 5.4233 - val_categorical_accuracy: 0.1971 - val_perplexity: 241.1074\n",
            "Epoch 27/50\n",
            "907/907 [==============================] - 212s 234ms/step - loss: 5.5748 - categorical_accuracy: 0.1708 - perplexity: 363.2986 - val_loss: 5.3784 - val_categorical_accuracy: 0.2025 - val_perplexity: 237.2117\n",
            "Epoch 28/50\n",
            "907/907 [==============================] - 212s 233ms/step - loss: 5.5987 - categorical_accuracy: 0.1685 - perplexity: 376.8730 - val_loss: 5.3910 - val_categorical_accuracy: 0.2012 - val_perplexity: 242.2883\n",
            "Epoch 29/50\n",
            "907/907 [==============================] - 212s 234ms/step - loss: 5.5625 - categorical_accuracy: 0.1715 - perplexity: 364.5222 - val_loss: 5.4133 - val_categorical_accuracy: 0.1995 - val_perplexity: 255.6211\n",
            "Epoch 30/50\n",
            "907/907 [==============================] - 211s 233ms/step - loss: 5.4577 - categorical_accuracy: 0.1798 - perplexity: 337.1323 - val_loss: 5.3445 - val_categorical_accuracy: 0.2058 - val_perplexity: 228.3590\n",
            "Epoch 31/50\n",
            "907/907 [==============================] - 212s 233ms/step - loss: 5.4935 - categorical_accuracy: 0.1770 - perplexity: 342.6416 - val_loss: 5.4184 - val_categorical_accuracy: 0.2009 - val_perplexity: 249.3570\n",
            "Epoch 32/50\n",
            "907/907 [==============================] - 211s 233ms/step - loss: 5.4931 - categorical_accuracy: 0.1767 - perplexity: 347.0768 - val_loss: 5.4193 - val_categorical_accuracy: 0.2005 - val_perplexity: 249.1023\n",
            "Epoch 33/50\n",
            "907/907 [==============================] - 211s 233ms/step - loss: 5.5757 - categorical_accuracy: 0.1695 - perplexity: 363.1942 - val_loss: 5.3735 - val_categorical_accuracy: 0.2047 - val_perplexity: 236.9756\n",
            "Epoch 34/50\n",
            "907/907 [==============================] - 211s 233ms/step - loss: 5.5028 - categorical_accuracy: 0.1762 - perplexity: 343.8968 - val_loss: 5.3308 - val_categorical_accuracy: 0.2075 - val_perplexity: 228.0092\n",
            "Epoch 35/50\n",
            "907/907 [==============================] - 210s 232ms/step - loss: 5.4657 - categorical_accuracy: 0.1792 - perplexity: 343.7621 - val_loss: 5.3185 - val_categorical_accuracy: 0.2077 - val_perplexity: 220.6494\n",
            "Epoch 36/50\n",
            "907/907 [==============================] - 212s 234ms/step - loss: 5.4703 - categorical_accuracy: 0.1788 - perplexity: 332.3503 - val_loss: 5.3380 - val_categorical_accuracy: 0.2065 - val_perplexity: 229.5672\n",
            "Epoch 37/50\n",
            "907/907 [==============================] - 211s 233ms/step - loss: 5.5301 - categorical_accuracy: 0.1738 - perplexity: 359.8935 - val_loss: 5.3505 - val_categorical_accuracy: 0.2056 - val_perplexity: 249.3120\n",
            "Epoch 38/50\n",
            "907/907 [==============================] - 211s 233ms/step - loss: 5.4272 - categorical_accuracy: 0.1823 - perplexity: 325.3779 - val_loss: 5.3313 - val_categorical_accuracy: 0.2094 - val_perplexity: 226.6420\n",
            "Epoch 39/50\n",
            "907/907 [==============================] - 212s 233ms/step - loss: 5.3821 - categorical_accuracy: 0.1858 - perplexity: 318.7712 - val_loss: 5.4433 - val_categorical_accuracy: 0.1981 - val_perplexity: 257.4593\n",
            "Epoch 40/50\n",
            "907/907 [==============================] - 212s 233ms/step - loss: 5.5293 - categorical_accuracy: 0.1739 - perplexity: 370.1786 - val_loss: 5.4034 - val_categorical_accuracy: 0.2031 - val_perplexity: 241.1452\n",
            "Epoch 41/50\n",
            "907/907 [==============================] - 212s 234ms/step - loss: 5.5268 - categorical_accuracy: 0.1729 - perplexity: 370.1700 - val_loss: 5.4501 - val_categorical_accuracy: 0.1998 - val_perplexity: 250.5063\n",
            "Epoch 42/50\n",
            "907/907 [==============================] - 209s 231ms/step - loss: 5.5997 - categorical_accuracy: 0.1660 - perplexity: 387.8069 - val_loss: 5.3973 - val_categorical_accuracy: 0.2054 - val_perplexity: 237.6881\n",
            "Epoch 43/50\n",
            "907/907 [==============================] - 212s 233ms/step - loss: 5.4510 - categorical_accuracy: 0.1794 - perplexity: 342.9338 - val_loss: 5.3416 - val_categorical_accuracy: 0.2070 - val_perplexity: 229.4993\n",
            "Epoch 44/50\n",
            "907/907 [==============================] - 211s 233ms/step - loss: 5.4312 - categorical_accuracy: 0.1811 - perplexity: 335.7990 - val_loss: 5.3881 - val_categorical_accuracy: 0.2033 - val_perplexity: 243.1623\n",
            "Epoch 45/50\n",
            "907/907 [==============================] - 211s 233ms/step - loss: 5.3606 - categorical_accuracy: 0.1874 - perplexity: 322.2759 - val_loss: 5.4008 - val_categorical_accuracy: 0.2039 - val_perplexity: 250.1987\n",
            "Epoch 46/50\n",
            "907/907 [==============================] - 211s 232ms/step - loss: 5.3590 - categorical_accuracy: 0.1878 - perplexity: 317.3987 - val_loss: 5.2433 - val_categorical_accuracy: 0.2158 - val_perplexity: 212.3593\n",
            "Epoch 47/50\n",
            "907/907 [==============================] - 211s 233ms/step - loss: 5.4239 - categorical_accuracy: 0.1817 - perplexity: 335.5000 - val_loss: 5.3031 - val_categorical_accuracy: 0.2131 - val_perplexity: 230.7609\n",
            "Epoch 48/50\n",
            "907/907 [==============================] - 213s 235ms/step - loss: 5.3316 - categorical_accuracy: 0.1900 - perplexity: 310.8685 - val_loss: 5.3137 - val_categorical_accuracy: 0.2121 - val_perplexity: 222.0290\n",
            "Epoch 49/50\n",
            "907/907 [==============================] - 212s 233ms/step - loss: 5.3716 - categorical_accuracy: 0.1865 - perplexity: 324.0692 - val_loss: 5.3782 - val_categorical_accuracy: 0.2065 - val_perplexity: 237.1642\n",
            "Epoch 50/50\n",
            "907/907 [==============================] - 212s 234ms/step - loss: 5.3539 - categorical_accuracy: 0.1888 - perplexity: 325.8540 - val_loss: 5.3359 - val_categorical_accuracy: 0.2108 - val_perplexity: 233.1062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2KSX5TiumnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(data_path + \"/final_model.hdf5\")\n",
        "with open(data_path+'/trainHistoryDict', 'wb') as file_pi:\n",
        "        pickle.dump(callback_history.history, file_pi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lv0giv16usan",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(callback_history.history['perplexity'])\n",
        "plt.plot(callback_history.history['val_perplexity'])\n",
        "plt.title('Model Perplexity')\n",
        "plt.ylabel('Perplexity')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.savefig('nn_4_50.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nInyrqouyt5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "852b894c-ea9e-4a53-d238-dbd824a619c0"
      },
      "source": [
        "import random\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "def predict(data, num_predict=300):\n",
        "    generated = ''\n",
        "    start_index = random.randint(0, len(data) - num_steps - 1)\n",
        "    # finding seed data by randomly selecting an index\n",
        "    sequence = data[start_index: start_index + num_steps]\n",
        "    for i in sequence:\n",
        "        generated += reversed_dictionary[i]\n",
        "        \n",
        "    sequence = np.array([sequence])\n",
        "    print('----- Generating with seed: \"' + generated + '\"')\n",
        "    print()\n",
        "    \n",
        "    seq = sequence\n",
        "    for i in range(num_predict):\n",
        "\n",
        "        predictions = model.predict(seq)\n",
        "        predicted_id = sample(predictions[:, num_steps-1, :][0])\n",
        "        \n",
        "        predict_word = np.argmax(predictions[:, num_steps-1, :])\n",
        "        generated += reversed_dictionary[predict_word] + \" \"\n",
        "        \n",
        "        seq = np.array([np.append(seq[0][1:], [predicted_id])])\n",
        "        \n",
        "    return generated\n",
        "\t\n",
        "print(predict(test_data))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----- Generating with seed: \"gastofeedincreasedelectricaldemandfromair<unk>use<eos>thissummerontheotherhandhad<unk>weatherthanusual<eos>we'vebeenverydisappointedintheperformanceof\"\n",
            "\n",
            "gastofeedincreasedelectricaldemandfromair<unk>use<eos>thissummerontheotherhandhad<unk>weatherthanusual<eos>we'vebeenverydisappointedintheperformanceofthe <eos> are have to a be the <unk> <eos> been the <eos> <unk> <eos> the <unk> and year <eos> the <unk> <unk> <unk> <unk> is <unk> <eos> <eos> <unk> of in <unk> <unk> in <unk> <unk> <unk> <eos> the be the n million in with the <unk> of by the <unk> <unk> <unk> n <unk> <eos> <eos> <unk> the of the <unk> the <unk> <unk> of <unk> <unk> be the <unk> the <unk> <unk> for the <unk> 's <unk> and <eos> the <unk> <unk> <unk> the on the the to the <eos> the the <unk> of <eos> <unk> been a <unk> <unk> <unk> of to <eos> the n't <unk> the to <unk> <unk> <unk> <unk> <unk> <eos> n <eos> <unk> the <unk> of <eos> <eos> the the the <unk> the <unk> the as <unk> <unk> of estate <unk> is <unk> <unk> for the <unk> <unk> <unk> <unk> to <unk> <eos> be <eos> the 're the of of <unk> <unk> the of <eos> <eos> the the the <unk> <unk> of to in the <unk> <unk> of the <unk> <eos> <unk> with the <unk> <unk> <eos> <unk> <unk> <eos> of <unk> <unk> the the companies are <unk> <unk> the 's the <eos> the the income $ <unk> <unk> <unk> <unk> <unk> is the <unk> are the than the the the and the <unk> <unk> <unk> the <unk> war <eos> the <eos> the the the the <unk> that <unk> a the the past n the <unk> <eos> the time n <eos> <unk> year <eos> <unk> to the that 're the of ago said to n to <unk> <eos> the <unk> <unk> 's a <unk> the the to 's the <unk> the the <unk> <unk> held <unk> been be <unk> of by <unk> market composite <eos> the <unk> said <unk> and <unk> <unk> \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}